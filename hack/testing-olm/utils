#!/bin/bash

millisecond=1
second=$(( 1000 * millisecond ))
minute=$(( 60 * second ))

LOGGING_NS="openshift-logging"

gather_logging_resources() {
  set +e
  local LOGGING_NS=$1
  local outdir=${2:-$ARTIFACT_DIR}
  local runtime=${3:-$(date +%s)}
  outdir=$outdir/$runtime
  mkdir $outdir ||:
  oc -n ${LOGGING_NS} get configmaps -o yaml > $outdir/configmaps.yaml 2>&1 || :
  oc -n ${LOGGING_NS} get secrets -o yaml > $outdir/secrets.yaml 2>&1 || :
  oc -n ${LOGGING_NS} get cronjobs -o yaml > $outdir/cronjobs.yaml 2>&1 || :
  
  oc -n ${LOGGING_NS} get deployments -o wide > $outdir/deployments.txt 2>&1 ||    :
  oc -n ${LOGGING_NS} get ds -o wide > $outdir/daemonsets.txt 2>&1 ||    :
  oc -n ${LOGGING_NS} get pods -o wide > $outdir/pods.txt 2>&1 || :
  oc -n ${LOGGING_NS} get clusterlogging instance -o yaml > $outdir/clusterlogging.instance.yaml  ||:
  oc -n ${LOGGING_NS} get clusterlogforwarder instance -o yaml > $outdir/clusterlogforwarder.instance.yaml  ||:

  oc -n ${LOGGING_NS} extract secret/elasticsearch --to=$outdir ||:
  oc -n ${LOGGING_NS} extract configmap/fluentd --to=$outdir ||:
  oc -n ${LOGGING_NS} extract configmap/secure-forward --to=$outdir ||:
  oc -n ${LOGGING_NS} extract secret/secure-forward --to=$outdir ||:

  oc -n ${LOGGING_NS} describe ds/fluentd > $outdir/fluentd.describe.txt  ||:
  

  oc -n openshift-logging exec -c elasticsearch \
    $(oc -n openshift-logging get pods -l component=elasticsearch -o jsonpath={.items[0].metadata.name}) \
    -- indices > $outdir/indices.txt||:
  for p in $(oc -n openshift-logging get pods -l component=fluentd -o jsonpath={.items[*].metadata.name}); do
    oc -n openshift-logging exec -- ls -l /var/lib/fluentd/clo_default_output_es > $outdir/$p.buffers.txt||:
    oc -n openshift-logging exec -- ls -l /var/lib/fluentd/retry_clo_default_output_es > $outdir/$p.buffers.retry.txt||:
  done

  oc -n openshift-operators-redhat get deployment elasticsearch-operator -o wide > $outdir/eo-deployment.txt 2>&1 || :
  oc -n openshift-operators-redhat describe deployment elasticsearch-operator > $outdir/eo-deployment.describe 2>&1 || :
  oc -n openshift-operators-redhat logs deployment/elasticsearch-operator > $outdir/elasticsearch-operator.logs 2>&1 || :

  get_all_logging_pod_logs $outdir
  get_all_olm_logs $outdir
  set -e
}

get_all_logging_pod_logs() {
  set +e
  local outdir=${1:-$ARTIFACT_DIR}
  local p
  local container
  for p in $(oc get pods -n ${LOGGING_NS} -o jsonpath='{.items[*].metadata.name}') ; do
    oc -n ${LOGGING_NS} describe pod $p > $outdir/$p.describe 2>&1 || :
    oc -n ${LOGGING_NS} get pod $p -o yaml > $outdir/$p.yaml 2>&1 || :

    initContainers=$(oc -n ${LOGGING_NS} get po $p -o jsonpath='{.spec.initContainers[*].name}')
    for container in $initContainers ; do
        oc logs -n ${LOGGING_NS} -c $container $p > $outdir/$p.$container.init.log 2>&1
    done

    containers="$(oc -n ${LOGGING_NS} get po $p -o jsonpath='{.spec.containers[*].name}')"
    for container in $containers ; do
      oc logs -n ${LOGGING_NS} -c $container $p > $outdir/$p.$container.log 2>&1
      case "$container" in
        fluentd*) oc -n ${LOGGING_NS} exec $p -- logs > $outdir/$p.$container.exec.log 2>&1 ;;
        elasticsearch*) oc -n ${LOGGING_NS}  exec -c elasticsearch $p  -- logs > $outdir/$p.$container.exec.log 2>&1 ;;
        *) continue ;;
      esac
    done
  done
  set -e
}

get_all_olm_logs(){
    set +e
    local outdir=${1:-$ARTIFACT_DIR}
    local runtime=${2:-"120s"}
    oc  -n openshift-operator-lifecycle-manager logs --since=$runtime deployment/catalog-operator > $outdir/catalog-operator.logs 2>&1
    oc  -n openshift-operator-lifecycle-manager logs --since=$runtime deployment/olm-operator > $outdir/olm-operator.logs 2>&1
    set -e
}
